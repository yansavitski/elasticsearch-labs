{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yansavitski/elasticsearch-labs/blob/main/Integration_Langchain_AWS_Bedrock_and_Elasticsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration AWS Bedrock\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/langchain/langchain-vector-store-using-elser.ipynb)\n",
        "\n",
        "\n",
        "This workbook demonstrates how to work with Langchain [Amazon Bedrock](https://aws.amazon.com/bedrock/). Amazon Bedrock is a managed service that makes foundation models from leading AI startup and Amazon's own Titan models available through APIs.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IQt5lMKvxios"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages and import modules"
      ],
      "metadata": {
        "id": "fWuHgEHjyRMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages\n",
        "!python3 -m pip install -qU langchain elasticsearch boto3\n",
        "\n",
        "# import modules\n",
        "from getpass import getpass\n",
        "from urllib.request import urlopen\n",
        "from langchain.vectorstores import ElasticsearchStore\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
        "from langchain.llms import Bedrock\n",
        "from langchain.chains import RetrievalQA\n",
        "import boto3\n",
        "import json"
      ],
      "metadata": {
        "id": "7byqCX6VyWYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: boto3 is part of AWS SDK for Python and is required to use Bedrock LLM"
      ],
      "metadata": {
        "id": "bWCXMAi58M3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init Bedrock client\n",
        "\n",
        "To authorize in AWS service we can use `~/.aws/config` file with [configuring credentials](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#configuring-credentials) or pass `AWS_ACCESS_KEY`, `AWS_SECRET_KEY`, `AWS_REGION` to boto3 module.\n",
        "\n",
        "We're using second approach for our example."
      ],
      "metadata": {
        "id": "F84cH96QqG6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_region = \"us-east-1\"\n",
        "AWS_ACCESS_KEY = getpass(\"AWS Acces key: \")\n",
        "AWS_SECRET_KEY = getpass(\"AWS Secret key: \")\n",
        "AWS_REGION = input(f\"AWS Region [default: {default_region}]: \") or default_region\n",
        "\n",
        "bedrock_client = boto3.client(service_name=\"bedrock-runtime\", region_name=AWS_REGION, aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n"
      ],
      "metadata": {
        "id": "kG76APtmp6dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Elasticsearch\n",
        "\n",
        "ℹ️ We're using an Elastic Cloud deployment of Elasticsearch for this notebook. If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial.\n",
        "\n",
        "We'll use the **Cloud ID** to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
        "\n",
        "\n",
        "We will use [ElasticsearchStore](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html) to connect to our elastic cloud deployment. This would help create and index data easily. In the ElasticsearchStore instance, will set embedding to [BedrockEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.bedrock.BedrockEmbeddings.html) to embed the texts and elasticsearch index name that will be used in this example. In the instance, we will set `strategy` to [ElasticsearchStore.SparseVectorRetrievalStrategy()](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.SparseRetrievalStrategy.html#langchain.vectorstores.elasticsearch.SparseRetrievalStrategy) as we use this strategy to split documents."
      ],
      "metadata": {
        "id": "Utg-ZqS_QS1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set elastic cloud id and password\n",
        "CLOUD_ID = getpass(\"Elastic deployment Cloud ID: \")\n",
        "CLOUD_USERNAME = \"elastic\"\n",
        "CLOUD_PASSWORD = getpass(\"Elastic deployment Password: \")\n",
        "\n",
        "embeddings = BedrockEmbeddings(client=bedrock_client)\n",
        "\n",
        "vector_store = ElasticsearchStore(es_cloud_id=CLOUD_ID, es_user=CLOUD_USERNAME, es_password=CLOUD_PASSWORD,\n",
        "            index_name= \"workplace_index\",\n",
        "            embedding=embeddings,\n",
        "            strategy=ElasticsearchStore.SparseVectorRetrievalStrategy()\n",
        "        )\n"
      ],
      "metadata": {
        "id": "idJiMEZpQfP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset\n",
        "\n",
        "Let's download the sample dataset and deserialize the document."
      ],
      "metadata": {
        "id": "qAkNwd_lQ7HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/workplace-search/data/data.json\"\n",
        "\n",
        "response = urlopen(url)\n",
        "\n",
        "workplace_docs = json.loads(response.read())\n"
      ],
      "metadata": {
        "id": "sjwpw_IxQ72L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Documents into Passages\n",
        "\n",
        "We’ll chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
        "\n",
        "Here we are chunking documents into 500 token passages with an overlap of 0 tokens.\n",
        "\n",
        "Here we are using a simple splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
      ],
      "metadata": {
        "id": "YWCTPOgnRHiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = []\n",
        "content = []\n",
        "\n",
        "for doc in workplace_docs:\n",
        "  content.append(doc[\"content\"])\n",
        "  metadata.append({\n",
        "      \"name\": doc[\"name\"],\n",
        "      \"summary\": doc[\"summary\"],\n",
        "      \"rolePermissions\":doc[\"rolePermissions\"]\n",
        "  })\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=400)\n",
        "docs = text_splitter.create_documents(content, metadatas=metadata)"
      ],
      "metadata": {
        "id": "mAtGD7GjRIIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index data into elasticsearch\n",
        "\n",
        "Next, we will index data to elasticsearch using [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents). We will use Cloud ID,  Password and Index name values set in the `Create cloud deployment` step.\n",
        "\n",
        "In the instance, we will set `strategy` to [ElasticsearchStore.SparseVectorRetrievalStrategy()](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.SparseRetrievalStrategy.html#langchain.vectorstores.elasticsearch.SparseRetrievalStrategy)\n",
        "\n",
        "Note: Before we begin indexing, ensure you have [downloaded and deployed ELSER model](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html#download-deploy-elser) in your deployment and is running in ml node.\n"
      ],
      "metadata": {
        "id": "MRXt1tnXRK_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = vector_store.from_documents(\n",
        "    docs, es_cloud_id=CLOUD_ID, es_user=CLOUD_USERNAME, es_password=CLOUD_PASSWORD, index_name=\"workplace_index\",\n",
        "    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy()\n",
        ")"
      ],
      "metadata": {
        "id": "-T2P8_ltRNgy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init Bedrock LLM\n",
        "\n",
        "Next, we will initialize Bedrock LLM. In the Bedrock instance, will pass `bedrock_client` and specific `model_id`: `amazon.titan-text-express-v1`, `ai21.j2-ultra-v1`, `anthropic.claude-v2`, `cohere.command-text-v14` or etc. You can see list of available base models on [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html)"
      ],
      "metadata": {
        "id": "azqaOaChswVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_model_id = \"amazon.titan-text-express-v1\"\n",
        "AWS_MODEL_ID = input(f\"AWS model [default: {default_model_id}]: \") or default_model_id\n",
        "llm = Bedrock(\n",
        "    client=bedrock_client,\n",
        "    model_id=AWS_MODEL_ID\n",
        ")"
      ],
      "metadata": {
        "id": "fRtZ_dfXsjaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asking a question\n",
        "Now that we have the passages stored in Elasticsearch and llm is initialized, we can now ask a question to get the relevant passages."
      ],
      "metadata": {
        "id": "9UZskhJRRTQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "ans = qa({\"query\": \"what is the nasa sales team?\"})\n",
        "\n",
        "print(\"\\033[92m ---- Answer ---- \\033[0m\")\n",
        "print(ans[\"result\"] + \"\\n\")\n",
        "print(\"\\033[94m ---- Sources ---- \\033[0m\")\n",
        "for doc in ans[\"source_documents\"]:\n",
        "  print(\"Name: \" + doc.metadata[\"name\"])\n",
        "  print(\"Content: \"+ doc.page_content)\n",
        "  print(\"-------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWGfbz2TkuJt",
        "outputId": "609e8794-08de-4bb0-ab37-db97c2fa163e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m ---- Answer ---- \u001b[0m\n",
            " North America South America region (NASA)\n",
            "\n",
            "\u001b[94m ---- Sources ---- \u001b[0m\n",
            "Name: Sales Organization Overview\n",
            "Content: Our sales organization is structured to effectively serve our customers and achieve our business objectives across multiple regions. The organization is divided into the following main regions:\n",
            "\n",
            "The Americas: This region includes the United States, Canada, Mexico, as well as Central and South America. The North America South America region (NASA) has two Area Vice-Presidents: Laura Martinez is the Area Vice-President of North America, and Gary Johnson is the Area Vice-President of South America.\n",
            "------- \n",
            "\n",
            "Name: Sales Organization Overview\n",
            "Content: Each regional sales team consists of dedicated account managers, sales representatives, and support staff, led by their respective Area Vice-Presidents. They are responsible for identifying and pursuing new business opportunities, nurturing existing client relationships, and ensuring customer satisfaction. The teams collaborate closely with other departments, such as marketing, product development, and customer support, to ensure we consistently deliver high-quality products and services to our clients.\n",
            "------- \n",
            "\n",
            "Name: Sales Engineering Collaboration\n",
            "Content: Title: Working with the Sales Team as an Engineer in a Tech Company\n",
            "\n",
            "Introduction:\n",
            "As an engineer in a tech company, collaboration with the sales team is essential to ensure the success of the company's products and services. This guidance document aims to provide an overview of how engineers can effectively work with the sales team, fostering a positive and productive working environment.\n",
            "Understanding the Sales Team's Role:\n",
            "The sales team is responsible for promoting and selling the company's products and services to potential clients. Their role involves establishing relationships with customers, understanding their needs, and ensuring that the offered solutions align with their requirements.\n",
            "------- \n",
            "\n",
            "Name: Sales Engineering Collaboration\n",
            "Content: By working together, both the engineering and sales teams can contribute to the overall success of the company.\n",
            "\n",
            "Conclusion:\n",
            "Collaboration between engineers and the sales team is crucial for a tech company's success. By understanding each other's roles, maintaining effective communication, collaborating on projects, and supporting one another, both teams can work together to achieve the company's goals and ensure customer satisfaction.\n",
            "------- \n",
            "\n"
          ]
        }
      ]
    }
  ]
}